{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tangent - automatic differentiation library\n",
    "\n",
    "If you've ever had to write down the differentiations manually, you know how painful and slow it can be.\n",
    "\n",
    "I found [this page](http://cs231n.github.io/optimization-2/) from CS231n stanford course really useful when I started learning about neural networks.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/google/tangent/master/docs/sct-ad-tf.gif\">\n",
    "\n",
    "[Tangent](https://github.com/google/tangent) isn't the first such library, but it's certainly very easy to use. It uses the Abstract Syntax Tree (AST) of the function. Once it has the AST, it can simply walk in the reverse order to compute the gradient.\n",
    "\n",
    "### Usage\n",
    "It's very easy to use:\n",
    "```python\n",
    "import tangent\n",
    "def f(x):\n",
    "    a = x * x\n",
    "    b = x\n",
    "    return a + b\n",
    "df = tangent.grad(f)\n",
    "```\n",
    "\n",
    "`df` in the above example is derivative wrt x. By default, derivative wrt the first argument is computed.\n",
    "\n",
    "\n",
    "### Pros\n",
    "* **Supports native python operations**: This makes it very easy to use compared to [Tensorflow](https://www.tensorflow.org/) or [Pytorch](http://pytorch.org/).\n",
    "* **Supports numpy/tensorflow-eager functions**: Gradient operations for the tensorflow-eager/numpy are built-in.\n",
    "* **Higher Order Gradients**: You can easily do higher order gradients by simply taking a `grad` of a `grad`.\n",
    "\n",
    "### Cons\n",
    "* Doesn't support classes yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardik/h/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tangent\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reverse mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def dfdx(x, y, b_return=1.0):\n",
      "    x_times_x = x * x\n",
      "\n",
      "    # Grad of: _return = x_times_x + y_times_y\n",
      "    _bx_times_x = tangent.unbroadcast(b_return, x_times_x)\n",
      "    bx_times_x = _bx_times_x\n",
      "\n",
      "    # Grad of: x_times_x = x * x\n",
      "    _bx = tangent.unbroadcast(bx_times_x * x, x)\n",
      "    _bx2 = tangent.unbroadcast(bx_times_x * x, x)\n",
      "    bx = _bx\n",
      "    bx = tangent.add_grad(bx, _bx2)\n",
      "    return bx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def f(x, y):\n",
    "    return x * x + y * y\n",
    "\n",
    "dfdx = tangent.grad(f, wrt=(0,), mode='reverse', verbose=True)\n",
    "dfdy = tangent.grad(f, wrt=(1,), mode='reverse', verbose=False)\n",
    "dfdxy = tangent.grad(f, wrt=(0, 1), mode='reverse', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know `dfdx` is `2 * x` and `dfdy` is `2 * y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x, y): 32\n",
      "dfdx: 8.0\n",
      "dfdy: 8.0\n",
      "dfdxy: (8.0, 8.0)\n"
     ]
    }
   ],
   "source": [
    "print('f(x, y):', f(4, 4))\n",
    "print('dfdx:', dfdx(4, 4))\n",
    "print('dfdy:', dfdx(4, 4))\n",
    "print('dfdxy:', dfdxy(4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditionals\n",
    "In this example, we will see how Tangent handles if/else statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def dfdy(x, y, bz=1.0):\n",
      "    # Initialize the tape\n",
      "    _stack = tangent.Stack()\n",
      "    _z = None\n",
      "    _3_times_y = None\n",
      "    _2_times_x = None\n",
      "\n",
      "    # Beginning of forward pass\n",
      "    cond = x > 2\n",
      "    if cond:\n",
      "        _2_times_x = 2 * x\n",
      "    else:\n",
      "        _3_times_y = 3 * y\n",
      "        _z = _3_times_y * y\n",
      "    tangent.push(_stack, cond, '_236eb625')\n",
      "\n",
      "    # Beginning of backward pass\n",
      "    cond = tangent.pop(_stack, '_236eb625')\n",
      "    if cond:\n",
      "        # Grad of: z = 2 * x * y\n",
      "        _by = tangent.unbroadcast(bz * _2_times_x, y)\n",
      "        by = _by\n",
      "    else:\n",
      "        # Grad of: z = x * x + 3 * y * y\n",
      "        _b_z = tangent.unbroadcast(bz, _z)\n",
      "        b_z = _b_z\n",
      "        _b_3_times_y = tangent.unbroadcast(b_z * y, _3_times_y)\n",
      "        _by3 = tangent.unbroadcast(b_z * _3_times_y, y)\n",
      "        b_3_times_y = _b_3_times_y\n",
      "        by = _by3\n",
      "        _by2 = tangent.unbroadcast(b_3_times_y * 3, y)\n",
      "        by = tangent.add_grad(by, _by2)\n",
      "    return by\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def f(x, y):\n",
    "    if x > 2:\n",
    "        z = 2 * x * y\n",
    "    else:\n",
    "        z = x * x + 3 * y * y\n",
    "    return z\n",
    "\n",
    "dfdy = tangent.grad(f, wrt=(1,), mode='reverse', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfdy(4,4) (Expected: 2 * x): 8.0\n",
      "dfdy(1,4) (Expected: 3 * 2 * y): 8.0\n"
     ]
    }
   ],
   "source": [
    "print('dfdy(4,4) (Expected: 2 * x):', dfdy(4, 4))\n",
    "print('dfdy(1,4) (Expected: 3 * 2 * y):', dfdy(1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it fails. There seems to be a bunch of bugs like this. For example, if I don't assign `z` and directly return from the if/else, it fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "h_py3",
   "language": "python",
   "name": "h_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
